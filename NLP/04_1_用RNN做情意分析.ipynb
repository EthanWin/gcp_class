{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.5"
    },
    "colab": {
      "name": "04-1. 用RNN做情意分析.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMa_EnvAXNa1",
        "colab_type": "text"
      },
      "source": [
        "# 主題 04-1. 用RNN做情意分析\n",
        "\n",
        "我們終於要介紹三大神經網路的最後一個, 也就是 RNN。RNN 有不少的變型, 例如 LSTM 和 GRU 等等, 不過我們都通稱叫 RNN。RNN 是一種「有記憶」的神經網路, 非常適合時間序列啦, 或是不定長度的輸入資料。\n",
        "\n",
        "我們來看看怎麼樣用 RNN 做電影評論的「情意分析」, 也就是知道一則評論究竟是「正評」還是「負評」。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUxb2mYyXNa2",
        "colab_type": "text"
      },
      "source": [
        "## 1. 初始準備\n",
        "\n",
        "基本上和之前是一樣的, 我們就不再說明。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4XHYaMmYFW9",
        "colab_type": "code",
        "outputId": "939ff9bb-60f1-4128-b035-08629536ada4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/Shared\\ drives/鮭魚卵軍艦/aigo_農業局資料_20190707/source"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/Shared drives/鮭魚卵軍艦/aigo_農業局資料_20190707/source\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcYZfjnoYgiR",
        "colab_type": "code",
        "outputId": "7bec5381-a044-4665-ad46-971610ac6588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "! wget https://raw.githubusercontent.com/bojone/keras_lookahead/master/lookahead.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-29 06:19:35--  https://raw.githubusercontent.com/bojone/keras_lookahead/master/lookahead.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2582 (2.5K) [text/plain]\n",
            "Saving to: ‘lookahead.py’\n",
            "\n",
            "\rlookahead.py          0%[                    ]       0  --.-KB/s               \rlookahead.py        100%[===================>]   2.52K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2019-07-29 06:19:35 (3.30 MB/s) - ‘lookahead.py’ saved [2582/2582]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEkqYDcWXNa3",
        "colab_type": "code",
        "outputId": "0b7a91e4-ddcb-49a4-f130-ede8b8ebe214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%env KERAS_BACKEND=tensorflow\n",
        "from lookahead import *"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: KERAS_BACKEND=tensorflow\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbpresent": {
          "id": "a73ce944-1f06-4b48-91eb-da5ff43936f9"
        },
        "id": "mwCAwIX_XNa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztWIpEHJXNa9",
        "colab_type": "text"
      },
      "source": [
        "## 2. 讀入 IMDB 電影數據庫\n",
        "\n",
        "今天我們要評入 IMDB 電影數據庫影評的部份。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czXAbHLNXNa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import imdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhm2jUi8XNbA",
        "colab_type": "code",
        "outputId": "96b12846-0d59-4d29-d797-8b44e5eafec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-138b67050bdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/datasets/imdb.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(path, num_words, skip_top, maxlen, seed, start_char, oov_char, index_from, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m                     file_hash='599dadb1135973df5b59232a0e9a887c')\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 return format.read_array(bytes,\n\u001b[1;32m    261\u001b[0m                                          \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                                          pickle_kwargs=self.pickle_kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;31m# The array contained Python objects. We need to unpickle the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m             raise ValueError(\"Object arrays cannot be loaded when \"\n\u001b[0m\u001b[1;32m    697\u001b[0m                              \"allow_pickle=False\")\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpickle_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Object arrays cannot be loaded when allow_pickle=False"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSm98WsDXNbD",
        "colab_type": "text"
      },
      "source": [
        "要注意這裡我們限制只選「最常用」1 萬字, 也就是超過這範圍的就當不存在。這是文字分析常會做的事。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSNQkKBvXNbD",
        "colab_type": "code",
        "outputId": "08b3c99c-34f8-4f5d-ba16-e7c6aad53d4f",
        "colab": {}
      },
      "source": [
        "print(\"訓練資料總筆數 =\", len(x_train))\n",
        "print(\"測試資料總筆數 =\", len(x_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "訓練資料總筆數 = 25000\n",
            "測試資料總筆數 = 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwJOeCMlXNbG",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 輸入資料部份\n",
        "\n",
        "我們來看一下輸入部份長什麼樣子?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVcmYrGRXNbG",
        "colab_type": "code",
        "outputId": "ddb729ed-a58c-4a7c-a8f2-6cc4dd10624a",
        "colab": {}
      },
      "source": [
        "x_train[99]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 1230,\n",
              " 3765,\n",
              " 566,\n",
              " 97,\n",
              " 189,\n",
              " 102,\n",
              " 86,\n",
              " 7,\n",
              " 32,\n",
              " 4,\n",
              " 973,\n",
              " 16,\n",
              " 55,\n",
              " 355,\n",
              " 18,\n",
              " 14,\n",
              " 20,\n",
              " 4,\n",
              " 64,\n",
              " 542,\n",
              " 173,\n",
              " 16,\n",
              " 4,\n",
              " 893,\n",
              " 2115,\n",
              " 5376,\n",
              " 250,\n",
              " 39,\n",
              " 8013,\n",
              " 4,\n",
              " 1362,\n",
              " 2,\n",
              " 14,\n",
              " 102,\n",
              " 47,\n",
              " 57,\n",
              " 599,\n",
              " 633,\n",
              " 6,\n",
              " 1317,\n",
              " 2,\n",
              " 8,\n",
              " 6,\n",
              " 189,\n",
              " 20,\n",
              " 57,\n",
              " 206,\n",
              " 57,\n",
              " 116,\n",
              " 5,\n",
              " 57,\n",
              " 836,\n",
              " 82,\n",
              " 6,\n",
              " 1317,\n",
              " 2,\n",
              " 3728,\n",
              " 2,\n",
              " 9,\n",
              " 6,\n",
              " 52,\n",
              " 284,\n",
              " 21,\n",
              " 29,\n",
              " 9,\n",
              " 38,\n",
              " 2245,\n",
              " 5,\n",
              " 1044,\n",
              " 11,\n",
              " 14,\n",
              " 15,\n",
              " 45,\n",
              " 619,\n",
              " 50,\n",
              " 71,\n",
              " 6,\n",
              " 171,\n",
              " 531,\n",
              " 15,\n",
              " 71,\n",
              " 424,\n",
              " 8,\n",
              " 30,\n",
              " 163,\n",
              " 6211,\n",
              " 4,\n",
              " 1629,\n",
              " 189,\n",
              " 212,\n",
              " 102,\n",
              " 5,\n",
              " 57,\n",
              " 31,\n",
              " 1498,\n",
              " 11,\n",
              " 4,\n",
              " 311,\n",
              " 13,\n",
              " 197,\n",
              " 15,\n",
              " 14,\n",
              " 20,\n",
              " 16,\n",
              " 1150,\n",
              " 1479,\n",
              " 5,\n",
              " 13,\n",
              " 161,\n",
              " 990,\n",
              " 692,\n",
              " 5,\n",
              " 1706,\n",
              " 12,\n",
              " 69,\n",
              " 77,\n",
              " 1194,\n",
              " 8,\n",
              " 3245,\n",
              " 2001,\n",
              " 553,\n",
              " 67,\n",
              " 14,\n",
              " 20,\n",
              " 48,\n",
              " 25,\n",
              " 423,\n",
              " 13,\n",
              " 131,\n",
              " 124,\n",
              " 51,\n",
              " 25,\n",
              " 122,\n",
              " 236,\n",
              " 1506,\n",
              " 198,\n",
              " 4,\n",
              " 64,\n",
              " 552,\n",
              " 7,\n",
              " 415,\n",
              " 37,\n",
              " 62,\n",
              " 169,\n",
              " 14,\n",
              " 20,\n",
              " 60,\n",
              " 2602,\n",
              " 629,\n",
              " 5,\n",
              " 615,\n",
              " 14,\n",
              " 9,\n",
              " 8,\n",
              " 25,\n",
              " 1230,\n",
              " 3765,\n",
              " 570,\n",
              " 231,\n",
              " 189,\n",
              " 102,\n",
              " 14,\n",
              " 20,\n",
              " 166,\n",
              " 2039,\n",
              " 168,\n",
              " 40,\n",
              " 2450,\n",
              " 5486,\n",
              " 3298]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNq36usAXNbJ",
        "colab_type": "text"
      },
      "source": [
        "注意這其實是一個 list 而不是 array, 原因是每筆資料 (每段影評) 長度自然是不一樣的! 我們檢查一下前 10 筆的長度就可以知道。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbAU1GP-XNbJ",
        "colab_type": "code",
        "outputId": "6da84ac1-b586-4ec4-b6b7-3898b69150c7",
        "colab": {}
      },
      "source": [
        "type(x_train[99])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odjoA3SgXNbM",
        "colab_type": "code",
        "outputId": "514cc304-de38-4dbd-b240-9684e09b2350",
        "colab": {}
      },
      "source": [
        "for i in range(10):\n",
        "    print(len(x_train[i]), end=', ')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "218, 189, 141, 550, 147, 43, 123, 562, 233, 130, "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEHRSf-RXNbO",
        "colab_type": "text"
      },
      "source": [
        "最後要說明的是, 在每筆輸入資料的數字都代表英文的一個單字。編號方式是在我們資料庫裡所有文字的排序: 也就是出現頻率越高, 代表的數字就越小。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZHoCBddXNbP",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 輸出資料部份\n",
        "\n",
        "輸出方面應該很容易想像, 我們來看看前 10 筆。結果自然就是 0 (負評) 或 1 (正評)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tiljj6zFXNbQ",
        "colab_type": "code",
        "outputId": "99d95b9f-cc4b-440d-ee9d-76e1c80cbe89",
        "colab": {}
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfNM9x5TXNbS",
        "colab_type": "text"
      },
      "source": [
        "### 2.3 送入神經網路的輸入處理\n",
        "\n",
        "雖然 RNN 是可以處理不同長度的輸入, 在寫程式時我們還是要\n",
        "\n",
        "* 設輸入文字長度的上限\n",
        "* 把每段文字都弄成一樣長, 太短的後面補上 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1Yr1G2HXNbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amdQIGQxXNbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = sequence.pad_sequences(x_train, maxlen=100)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb8wjA8CXNbY",
        "colab_type": "code",
        "outputId": "7221c7cd-31a4-4171-87c8-12feea55a47e",
        "colab": {}
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDgpLy7JXNba",
        "colab_type": "code",
        "outputId": "d0af4a5b-7940-4744-d216-121b688d7207",
        "colab": {}
      },
      "source": [
        "x_train[99]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  14,   15,   45,  619,   50,   71,    6,  171,  531,   15,   71,\n",
              "        424,    8,   30,  163, 6211,    4, 1629,  189,  212,  102,    5,\n",
              "         57,   31, 1498,   11,    4,  311,   13,  197,   15,   14,   20,\n",
              "         16, 1150, 1479,    5,   13,  161,  990,  692,    5, 1706,   12,\n",
              "         69,   77, 1194,    8, 3245, 2001,  553,   67,   14,   20,   48,\n",
              "         25,  423,   13,  131,  124,   51,   25,  122,  236, 1506,  198,\n",
              "          4,   64,  552,    7,  415,   37,   62,  169,   14,   20,   60,\n",
              "       2602,  629,    5,  615,   14,    9,    8,   25, 1230, 3765,  570,\n",
              "        231,  189,  102,   14,   20,  166, 2039,  168,   40, 2450, 5486,\n",
              "       3298], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHOH21WXXNbd",
        "colab_type": "text"
      },
      "source": [
        "至此我們可以來寫我們的第一個 RNN 了!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG6n5RbrXNbe",
        "colab_type": "text"
      },
      "source": [
        "## 3. 打造你的 RNN\n",
        "\n",
        "這裡我們選用 LSTM, 基本上用哪種 RNN 寫法都是差不多的!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2odBPzdXNbe",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 決定神經網路架構\n",
        "\n",
        "* 先將 10000 維的文字壓到 128 維\n",
        "* 然後用 128 個 LSTM\n",
        "* 最後一個 output, 直接用 sigmoid 送出"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6x16hfGXNbf",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 建構我們的神經網路\n",
        "\n",
        "文字我們用 1-hot 表示是很標準的方式, 不過要注意的是, 因為我們指定要 1 萬個字, 所以每個字是用 1 萬維的向量表示! 這一來很浪費記憶空間, 二來字和字間基本上是沒有關係的。我們可以用某種「合理」的方式, 把字壓到比較小的維度, 這些向量又代表某些意思 (比如說兩個字代表的向量角度小表相關程度大) 等等。\n",
        "\n",
        "這聽來很複雜的事叫 \"word embedding\", 而事實上 Keras 會幫我們做。我們只需告訴 Keras 原來最大的數字是多少 (10000), 還有我們打算壓到幾維 (128)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpR3dVnQXNbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbpresent": {
          "id": "924cda44-78f6-4bbc-a669-68e5bdeb4704"
        },
        "id": "3gYRd_QPXNbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbpresent": {
          "id": "654a314d-0144-4421-a293-3586e91cfedd"
        },
        "id": "s3MI93SXXNbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Embedding(10000, 128))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWj-4ChuXNbo",
        "colab_type": "text"
      },
      "source": [
        "LSTM 層, 我們做 150 個 LSTM Cells。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbpresent": {
          "id": "b8e3a157-5933-4b63-b156-fe4bdf8905a4"
        },
        "id": "MmFrbS5cXNbp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(LSTM(150))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkffvv_ZXNbr",
        "colab_type": "text"
      },
      "source": [
        "單純透過 sigmoid 輸出。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbpresent": {
          "id": "18b410f8-45b0-4188-95c2-c30cc76d07b8"
        },
        "id": "smmdKsmYXNbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJD_RBRzXNbt",
        "colab_type": "text"
      },
      "source": [
        "### 3.3 組裝\n",
        "\n",
        "這次我們用 binary_crossentropy 做我們的 loss function, 另外用一個很潮的 Adam 學習法。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbpresent": {
          "id": "9593a32d-9089-48fb-8e65-f39cb0137f08"
        },
        "id": "FsEXuWkaXNbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TMamczLXNbw",
        "colab_type": "text"
      },
      "source": [
        "## 4. 訓練"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4SOG7XiXNbx",
        "colab_type": "text"
      },
      "source": [
        "我們用的 embedding 中, 會被 batch_size 影響輸入。輸入的 shape 會是\n",
        "\n",
        "    (batch_size, 每筆上限)\n",
        "    \n",
        "也就是 (32,100) 輸出是 (32,100,128), 其中 128 是我們決定要壓成幾維的向量。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbpresent": {
          "id": "29d4727a-4b5a-463c-9cc7-1a7df697e774"
        },
        "id": "DWtsKhfyXNbx",
        "colab_type": "code",
        "outputId": "80663427-923f-475e-fc56-eb3c68525f67",
        "colab": {}
      },
      "source": [
        "model.fit(x_train, y_train, \n",
        "          batch_size=32, \n",
        "          epochs=15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "25000/25000 [==============================] - 399s 16ms/step - loss: 0.4247 - acc: 0.8024\n",
            "Epoch 2/15\n",
            "25000/25000 [==============================] - 389s 16ms/step - loss: 0.2653 - acc: 0.8947\n",
            "Epoch 3/15\n",
            "25000/25000 [==============================] - 403s 16ms/step - loss: 0.1929 - acc: 0.9270\n",
            "Epoch 4/15\n",
            "25000/25000 [==============================] - 422s 17ms/step - loss: 0.1390 - acc: 0.9497\n",
            "Epoch 5/15\n",
            "25000/25000 [==============================] - 396s 16ms/step - loss: 0.1005 - acc: 0.9638\n",
            "Epoch 6/15\n",
            "25000/25000 [==============================] - 390s 16ms/step - loss: 0.0679 - acc: 0.9776\n",
            "Epoch 7/15\n",
            "25000/25000 [==============================] - 391s 16ms/step - loss: 0.0529 - acc: 0.9814\n",
            "Epoch 8/15\n",
            "25000/25000 [==============================] - 397s 16ms/step - loss: 0.0386 - acc: 0.9881\n",
            "Epoch 9/15\n",
            "25000/25000 [==============================] - 393s 16ms/step - loss: 0.0357 - acc: 0.9886\n",
            "Epoch 10/15\n",
            "25000/25000 [==============================] - 390s 16ms/step - loss: 0.0259 - acc: 0.9920\n",
            "Epoch 11/15\n",
            "25000/25000 [==============================] - 394s 16ms/step - loss: 0.0273 - acc: 0.9912\n",
            "Epoch 12/15\n",
            "25000/25000 [==============================] - 390s 16ms/step - loss: 0.0183 - acc: 0.9942\n",
            "Epoch 13/15\n",
            "25000/25000 [==============================] - 456s 18ms/step - loss: 0.0085 - acc: 0.9980\n",
            "Epoch 14/15\n",
            "25000/25000 [==============================] - 434s 17ms/step - loss: 0.0185 - acc: 0.9942\n",
            "Epoch 15/15\n",
            "25000/25000 [==============================] - 429s 17ms/step - loss: 0.0169 - acc: 0.9949\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x122e98240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQZSyZp_XNbz",
        "colab_type": "text"
      },
      "source": [
        "## 5. 檢視結果"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74s05FtHXNbz",
        "colab_type": "text"
      },
      "source": [
        "### 5.1 分數\n",
        "\n",
        "我們照例來看看測試資料的分數。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca_qZky3XNb0",
        "colab_type": "code",
        "outputId": "fd0a09c1-d134-4f8c-e3ae-b6bae27b8b3d",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 122s 5ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_bPFm8XXNb2",
        "colab_type": "code",
        "outputId": "332bfed2-a1bb-4b39-a1f5-d34c335c96aa",
        "colab": {}
      },
      "source": [
        "print('測試資料的 loss:', score[0])\n",
        "print('測試資料正確率:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "測試資料的 loss: 0.915229337259\n",
            "測試資料正確率: 0.82688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5sI3T5cXNb5",
        "colab_type": "text"
      },
      "source": [
        "### 5.2 儲存結果\n",
        "\n",
        "這裡有 8 成我們可以正確分辨, 看來還不差, 照例我們把結果存檔。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "nbpresent": {
          "id": "dbc1a7a3-89db-4cbf-872c-b8ebcd035037"
        },
        "id": "Vz1bYeNBXNb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_json = model.to_json()\n",
        "open('imdb_model_architecture.json', \n",
        "     'w').write(model_json)\n",
        "model.save_weights('imdb_model_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}